{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6664ebc6-6bb1-4a00-9e41-85455f040051",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scopes: ['https://www.googleapis.com/auth/cloud-platform']\n"
     ]
    }
   ],
   "source": [
    "#!pip install google-generativeai\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.service_account import Credentials\n",
    "API_KEY='AIzaSyBqgKjrXkuU5hU-PiYokFucduySJyUewR0'\n",
    "api_keypath_sa='badri-gcp-vertexai-6a4b740168ef.json'\n",
    "SCOPES = ['https://www.googleapis.com/auth/cloud-platform']\n",
    "\n",
    "credentials = Credentials.from_service_account_file(\n",
    "    api_keypath_sa,\n",
    "    scopes=SCOPES\n",
    ")\n",
    "\n",
    "print(\"Scopes:\", credentials.scopes)\n",
    "\n",
    "PROJECT_ID = \"badri-gcp-vertexai\"\n",
    "REGION = 'us-central1'\n",
    "\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(\n",
    "    project = PROJECT_ID,\n",
    "    location= REGION,  # or the region where your Vertex AI is deployed\n",
    "    credentials=credentials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "839b48fa-473c-470a-bbba-8f26b5d9b787",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\singh\\anaconda3\\Lib\\site-packages\\vertexai\\generative_models\\_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n"
     ]
    },
    {
     "ename": "NotFound",
     "evalue": "404 Publisher Model `projects/badri-gcp-vertexai/locations/us-central1/publishers/google/models/gemini-1.5-flash` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\grpc\\_interceptor.py:277\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    270\u001b[0m     request: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 277\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_with_call(\n\u001b[0;32m    278\u001b[0m         request,\n\u001b[0;32m    279\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    280\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m    281\u001b[0m         credentials\u001b[38;5;241m=\u001b[39mcredentials,\n\u001b[0;32m    282\u001b[0m         wait_for_ready\u001b[38;5;241m=\u001b[39mwait_for_ready,\n\u001b[0;32m    283\u001b[0m         compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    284\u001b[0m     )\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\grpc\\_interceptor.py:332\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m    329\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interceptor\u001b[38;5;241m.\u001b[39mintercept_unary_unary(\n\u001b[0;32m    330\u001b[0m     continuation, client_call_details, request\n\u001b[0;32m    331\u001b[0m )\n\u001b[1;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39mresult(), call\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\grpc\\_channel.py:440\u001b[0m, in \u001b[0;36m_InactiveRpcError.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See grpc.Future.result.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 440\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\grpc\\_interceptor.py:315\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[1;34m(new_details, request)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 315\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thunk(new_method)\u001b[38;5;241m.\u001b[39mwith_call(\n\u001b[0;32m    316\u001b[0m         request,\n\u001b[0;32m    317\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mnew_timeout,\n\u001b[0;32m    318\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mnew_metadata,\n\u001b[0;32m    319\u001b[0m         credentials\u001b[38;5;241m=\u001b[39mnew_credentials,\n\u001b[0;32m    320\u001b[0m         wait_for_ready\u001b[38;5;241m=\u001b[39mnew_wait_for_ready,\n\u001b[0;32m    321\u001b[0m         compression\u001b[38;5;241m=\u001b[39mnew_compression,\n\u001b[0;32m    322\u001b[0m     )\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\grpc\\_channel.py:1192\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1189\u001b[0m state, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[0;32m   1190\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[0;32m   1191\u001b[0m )\n\u001b[1;32m-> 1192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\grpc\\_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[1;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[0;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[1;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.NOT_FOUND\n\tdetails = \"Publisher Model `projects/badri-gcp-vertexai/locations/us-central1/publishers/google/models/gemini-1.5-flash` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B2607:f8b0:4006:81f::200a%5D:443 {grpc_message:\"Publisher Model `projects/badri-gcp-vertexai/locations/us-central1/publishers/google/models/gemini-1.5-flash` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions\", grpc_status:5}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 16\u001b[0m\n\u001b[0;32m      9\u001b[0m vertexai\u001b[38;5;241m.\u001b[39minit(\n\u001b[0;32m     10\u001b[0m     project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbadri-gcp-vertexai\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m     location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mus-central1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     credentials\u001b[38;5;241m=\u001b[39mcredentials\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m GenerativeModel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-1.5-flash\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m response \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate_content(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the capital of India?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\vertexai\\generative_models\\_generative_models.py:712\u001b[0m, in \u001b[0;36m_GenerativeModel.generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels, stream)\u001b[0m\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content_streaming(\n\u001b[0;32m    704\u001b[0m         contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[0;32m    705\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    709\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m    710\u001b[0m     )\n\u001b[0;32m    711\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 712\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content(\n\u001b[0;32m    713\u001b[0m         contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[0;32m    714\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m    715\u001b[0m         safety_settings\u001b[38;5;241m=\u001b[39msafety_settings,\n\u001b[0;32m    716\u001b[0m         tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[0;32m    717\u001b[0m         tool_config\u001b[38;5;241m=\u001b[39mtool_config,\n\u001b[0;32m    718\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m    719\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\vertexai\\generative_models\\_generative_models.py:837\u001b[0m, in \u001b[0;36m_GenerativeModel._generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generates content.\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \n\u001b[0;32m    812\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;124;03m    A single GenerationResponse object\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    829\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[0;32m    830\u001b[0m     contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[0;32m    831\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    835\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m    836\u001b[0m )\n\u001b[1;32m--> 837\u001b[0m gapic_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prediction_client\u001b[38;5;241m.\u001b[39mgenerate_content(request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_response(gapic_response)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\cloud\\aiplatform_v1\\services\\prediction_service\\client.py:2276\u001b[0m, in \u001b[0;36mPredictionServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m   2273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m   2275\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m-> 2276\u001b[0m response \u001b[38;5;241m=\u001b[39m rpc(\n\u001b[0;32m   2277\u001b[0m     request,\n\u001b[0;32m   2278\u001b[0m     retry\u001b[38;5;241m=\u001b[39mretry,\n\u001b[0;32m   2279\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m   2280\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m   2281\u001b[0m )\n\u001b[0;32m   2283\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m   2284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mNotFound\u001b[0m: 404 Publisher Model `projects/badri-gcp-vertexai/locations/us-central1/publishers/google/models/gemini-1.5-flash` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions"
     ]
    }
   ],
   "source": [
    "from google.oauth2.service_account import Credentials\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "\n",
    "api_keypath_sa = './badri-gcp-vertexai-6a4b740168ef.json'\n",
    "SCOPES = ['https://www.googleapis.com/auth/cloud-platform']\n",
    "credentials = Credentials.from_service_account_file(api_keypath_sa, scopes=SCOPES)\n",
    "\n",
    "vertexai.init(\n",
    "    project=\"badri-gcp-vertexai\",\n",
    "    location=\"us-central1\",\n",
    "    credentials=credentials\n",
    ")\n",
    "\n",
    "model = GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(\"What is the capital of India?\")\n",
    "print(response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "890e4a08-9831-4773-9bc2-ebd375eb8c3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Delhi is the capital of India.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Configure with API key\n",
    "genai.configure(api_key=\"AIzaSyC-u6YfpQP_uQsmaPDWEQIWgX3bnu8FgtE\")\n",
    "\n",
    "# ✅ Correct model name\n",
    "model = genai.GenerativeModel(\"models/gemini-1.5-pro\")\n",
    "\n",
    "# Send prompt\n",
    "#response = model.generate_content(\"Explain Vertex AI in simple terms.\")\n",
    "response = model.generate_content(\"Capital of india\")\n",
    "\n",
    "# Print the result\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b05b4b0-698f-4cb4-bdb1-c93402d30fb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IncompleteIterationError",
     "evalue": "Please let the response complete iteration before accessing the final accumulated\nattributes (or call `response.resolve()`)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIncompleteIterationError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mGenerativeModel(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/gemini-1.5-pro\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m response \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate_content(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExplain Vertex AI in simple terms.\u001b[39m\u001b[38;5;124m\"\u001b[39m,stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\generativeai\\types\\generation_types.py:463\u001b[0m, in \u001b[0;36mBaseGenerateContentResponse.text\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtext\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    458\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A quick accessor equivalent to `self.candidates[0].content.parts[0].text`\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \n\u001b[0;32m    460\u001b[0m \u001b[38;5;124;03m    Raises:\u001b[39;00m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;124;03m        ValueError: If the candidate list or parts list does not contain exactly one entry.\u001b[39;00m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 463\u001b[0m     parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparts\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parts:\n\u001b[0;32m    465\u001b[0m         candidate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcandidates[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\generativeai\\types\\generation_types.py:434\u001b[0m, in \u001b[0;36mBaseGenerateContentResponse.parts\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparts\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    429\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A quick accessor equivalent to `self.candidates[0].content.parts`\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \n\u001b[0;32m    431\u001b[0m \u001b[38;5;124;03m    Raises:\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;124;03m        ValueError: If the candidate list does not contain exactly one candidate.\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 434\u001b[0m     candidates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcandidates\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m candidates:\n\u001b[0;32m    436\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    437\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid operation: The `response.parts` quick accessor requires a single candidate, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    438\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut but `response.candidates` is empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    439\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\generativeai\\types\\generation_types.py:424\u001b[0m, in \u001b[0;36mBaseGenerateContentResponse.candidates\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"The list of candidate responses.\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \n\u001b[0;32m    420\u001b[0m \u001b[38;5;124;03mRaises:\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;124;03m    IncompleteIterationError: With `stream=True` if iteration over the stream was not completed.\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_done:\n\u001b[1;32m--> 424\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IncompleteIterationError(_INCOMPLETE_ITERATION_MESSAGE)\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mcandidates\n",
      "\u001b[1;31mIncompleteIterationError\u001b[0m: Please let the response complete iteration before accessing the final accumulated\nattributes (or call `response.resolve()`)"
     ]
    }
   ],
   "source": [
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key='AIzaSyC-u6YfpQP_uQsmaPDWEQIWgX3bnu8FgtE')\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"models/gemini-1.5-pro\")\n",
    "\n",
    "response = model.generate_content(\"Explain Vertex AI in simple terms.\",stream=True)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589f84d3-f6ab-4a8d-8166-3bf1e2aa4c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
